# Samples

Researchers are usually interested in the describing the attributes of a population; numbers that describe the population are called parameters. Two parameters that are frequently of interest are the mean and variance of the population.  Unfortunately,  it’s rarely possible to obtain information from every member of a population to calculate a parameter. Consequently, researchers use subsets of the population called samples to estimate parameters. Numbers calculated from sample data are called statistics. Typically, sample statistics are used to estimate population parameters.

Sample statistics, however, often differ from population parameters. The difference between a sample statistic and the population parameter occurs because the sample data is random subset of the population data — with correspondingly few observations. Sometimes the sample statistic will be higher than the population parameter; other times the sample statistic will be lower than the population parameter.  Because random sampling is used to select the sample data the direction and magnitude of the difference between the sample statistic the population parameter will vary randomly.

Further complicating matter is  the fact that the formula used for a sample statistic may or may not be the same as the formula used for the corresponding population parameter. This occurs because the purpose of the sample statistic is usually not to describe the sample. Rather the purpose of the sample statistic is to estimate the population parameter. Depending on the parameter, you may or may not be able to use the same formula with sample data as your would with the population data.

## Notation

In the formulas below, when we refer the population, we use uppercase letters when indicating members ($X$) or the size ($N$). In contrast, when we refer to the sample, we use lowercsae letters when indicating members ($x$) or the size ($n$).


## Estimating the mean

We are interested in sample means ($\bar{x}$) to the extent that they provide an estimate of the population mean ($\mu$). 

The population mean, $\mu$, is a parameter calculated using Formula \@ref(eq:popmeanch5)

\begin{equation} 
\mu = \frac{\sum{X}}{N}
      (\#eq:popmeanch5)
\end{equation} 

The sample mean, $\bar{x}$, is a statistic calculated using the using Formula \@ref(eq:samplemeanch5). The bar of above the $x$, indicates that it is a mean. Notice that the two formulas are the same - even though they use different notation.


\begin{equation} 
\bar{x} = \frac{\sum{x}}{n}
      (\#eq:samplemeanch5)
\end{equation} 

A sample mean is calculated using sample data which is a random subset of the population. Consequently, the sample mean (a statistic) is likely to differ the population mean (a parameter).  This difference between the sample mean and the population mean could potentially be concerning.  Statisticians know, however, that you can rarely learn anything from a single study or even a small set of studies. Consequently, they are more interested in what is true, on average, over a large number of studies. Keep this point in mind when conducting your own research.

One way of assessing the quality of the sample mean as an estimate of the population mean is by examining bias. If the average of many sample means is equal to the population mean, then we consider the sample mean to be an unbiased estimator of the population mean.

Fortunately, the average of many sample means does equal the population mean - so the sample mean is an unbiased estimator of the population mean. This fact can be illustrated with a computer simulation. 

We begin by activating the required packages:

```{r, include=FALSE}
library(tidyverse)
library(learnSampling)
```

```{r}
library(tidyverse)
library(learnSampling)
```

Next, we create a large population with 100,000 people using the get_height_population() command:

```{r}
pop_data <- get_height_population() 
```


We can use tidyverse commands to determine the mean of the population ($\mu$):

```{r}
pop_data %>%
  summarise(pop_mean = mean(height)) %>%
  as.data.frame()
```

We see that the mean of the population is $\mu = 172.48$. We can illustrate how random sampling works, with respect to estimating this population mean, by taking a large number of samples from the population.

In the code below, we use the get_M_samples() command to obtain 5000 samples, each composed of 10 people. For each of these 5000 samples we calculate a variety of statistics and place themm in the many_samples data frame. Each row of many_samples represents a sample of 10 people. Each column of many_samples indicates a sample statistic or the population parameter the statistic is estimating.


```{r}

# set.seed ensures you get the same random samples
set.seed(1) 

many_samples <- get_M_samples(pop.data = pop_data, 
                              data.column.name = height,
                              n = 10,
                              number.of.samples = 5000)
```

We use the head() command to see the first 10 rows (i.e., 10 samples of 5000 samples):

```{r}
head(many_samples, 10)
```

You can see the for each sample we indicate n (the sample size), pop.M (the mean of the population), sample.M (the mean of the sample), and a few other statistics. Because all the samples came from the same population you can that the population mean (pop.M) is constant across rows/samples. In contrast, the sample mean (sample.M) varies across samples due to random sampling error.

You can see the full extent to which the sample means vary by creating a graph with the code below. In this code, we use the pull() command to extract the value from the sample.M column and then we send them to the base R hisogram command, hist().

```{r}
many_samples %>%
 pull(sample.M) %>%
 hist(main = "Histogram of Sample Means")
```
 
 
You can see the 5000 sample means plotted in this graph. Recall the population mean for heights is $\mu = 172.48$ cm. Notice that most of the sample means cluster around this value. Also notice there is considerable variability about this value. Any given sample mean ($\bar{x}$) may differ substantially from the population mean ($\mu = 172.48$). This variability illustrates the challenges with learning something from a single study - particularly a study with a small sample size.

Statisticians, recognizing the limitations of a single study, are not particularly concerned if a single sample deviates from the popualtion mean. That said, statisticians are very concerned whether the results of a large number of studies are correct -- on average. That is, does the average of many sample means correspond to the population mean. If, on average, the sample mean is accurate we refer to it as an unbiased estimator. 

In the code below we calculate the average of the 5000 sample means to determine if the sample mean is an unbiased estimator.

```{r}
many_samples %>%
 summarise(mean_of_sample.M = mean(sample.M))
```

We find that the average of the 5000 sample means is 172.47 which is very close to the population mean of 172.48. Note that when we did this, we used the same formula to calculate the sample mean as we did the population mean. The average of the sample means was not identical to the population mean but it was very close - it would have been exactly the same with many more samples. Consequently, the sample mean provides an unbiased estimate of the population mean. In other words, it makes sense to use the sample mean as an estimate of the population mean. If we try to estimate the population mean with a sample mean we will, on average, be correct; although any given sample/study mean might be "wrong".


## Estimating variance

We are interested in sample variances ($s^2$) to the extent that they provide an estimate of the population mean ($\sigma^2$). Recall, the population variance, $\sigma^2$, is a parameter calculated using Formula \@ref(eq:popvarch5).

\begin{equation} 
\sigma^2 = \frac{\sum{(X - \mu)^2}}{N}
      (\#eq:popvarch5)
\end{equation} 


The sample variance, $s^2$, is a statistic calculated using Formula \@ref(eq:samplevarnch5). The formula is the same as at the population level but we use a different notation because it is a sample.

\begin{equation} 
s^2 = \frac{\sum{(x - \bar{x})^2}}{n}
      (\#eq:samplevarnch5)
\end{equation} 


Examine the output for 5000 samples we created using the head() command. Notice in this output we see the population variance is 157.46 (see the pop.var column):

```{r}
head(many_samples, 10)
```

Now inspect the sample.var.n column. In this column we present the sample variance calculated, using the above formula, with $n$ in the denominator. That is, in this column we have calculated sample variance using the same formula (but with different notation) as we used at the population level. Notice the values in the sample.var.n column vary due to random sampling.

As we did with the mean, we can take the average of the 5000 sample variances (each using $n$ in the denominator) to determine if the sample variance provides a biased or unbiased estimate of the population variance.

```{r}
many_samples %>%
 summarise(mean_of_var.n = mean(sample.var.n))
```

We find that the average of the 5000 sample variances is 141.86 which is not close to the population variance of 157.46. Note that when we did this, we used the same formula to calculate the sample variance as we did the population variance.

The average of the sample variances (141.86) was different from the population variancee (157.46). The average of the sample variance was much smaller than the population variance. Consequently, the sample variance provides a biased estimate of the population variance. If we try to estimate the population variance with a sample variance we will, on average, be wrong.

Fortunately, there is a way around the fact that the sample variance provides a biased estimate of the population variance. We can derive a formula at the sample level that estimate the population variance that is not biased (see Hayes). An unbiased estimate of the population variance can be obtained if we calculate the sample variance but divide by $n - 1$ instead of $n$. The unbiased estimate is calculated using Formula \@ref(eq:samplevarn1ch5).

\begin{equation} 
s^2 = \frac{\sum{(x - \bar{x})^2}}{n-1}
      (\#eq:samplevarn1ch5)
\end{equation} 

The column sample.var.n_1 contains an estimate of the population variance using $n-1$ in the denominator. Check out this column using the head() command:

```{r}
head(many_samples, 10)
```

We can evaluate the quality of this new variance formula, using $n-1$, by averaging over values in the sample.var.n_1 column.

```{r}
many_samples %>%
 summarise(mean_of_var.n_1 = mean(sample.var.n_1))
```

We see that the average of the 5000 values using $n-1$ in the denominator is 157.62 which is very close to the population varaince of 157.46. Consequently, we when we use $n-1$ in the denominator we have an unbiased estimate of the population variance. If we try to estimate the population variance with a sample variance, using $n-1$ in the denominator, we will, on average, be right.

You may wonder at this point, when I use $n-1$ in the denominator of the sample variance, can I still think of it as the average of the squared deviations from the mean. The short answer is yes. When you use $n-1$ in the denominator of the sample variance you are not calculating the variance for the group people in the sample. Rather, you are estimating the variance for the much larger group of people in the population. Consequently, it makes sense to think of sample variance, using $n-1$, as an estimate of the average of the squared errors in the population.

## Estimating standard deviation

Due to the above findings for variance, we tend to estimate the population standard deviation using Formula \@ref(eq:samplesd1ch5).

\begin{equation} 
s = \sqrt{\frac{\sum{(x - \bar{x})^2}}{n-1}}
      (\#eq:samplesd1ch5)
\end{equation} 


## Estimating SMD


