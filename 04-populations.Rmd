# Populations and samples

```{r, include=FALSE}
library(tidyverse)
```

## Required Packages

The following packages must be installed before starting this chapter.

| Required Packages |
|-------------------|
|tidyverse          |


## Notation

In this chapter we will use summation notation. If you are not familiar with summation notation, we present a brief overview here.

Consider a scenario where we have the IQ data for three participants We use the N symbol to represent the number of participants. Because we have three participants N = 3. The data for these participants is illustrated in Figure \@ref(fig:notationdata).

Notice how each person in the data set can be represent by the variable X. The first person by X_1, the second by X2, and the third by X_3. Often we refer to individuals in a data set by using the variable X accompanied by a subscript (e.g., 1, 2, 3, etc.).

```{r notationdata, echo = FALSE, out.width="55%", fig.cap = "Data for understanding summation notation"}
knitr::include_graphics("ch_populations/images/screenshot_data_n6.png")
```

Referring to participants using the variable X and subscript is valuable because it can be used in conjunction with the sigma (i.e., $\Sigma$) symbol for summation. Consider the example below in which we use the summation notation to indicate that we want to add all the X values (representing IQ) for the participants. We use a lower case $i$ to represent all possible subscript values. The notation below the $\Sigma$, $i$ = 1, indicates that we should start with participant 1. The notation below the $\Sigma$,  N, indicates that we should iterate $i$ up to the value indicated by N; in this case 3, because there are three participants.

$$
\begin{aligned} 
\sum_{i=1}^{N} X_i &=  X_1 + X_2 + X_3\\ 
&= 110 + 120 + 100 \\
&= 330
\end{aligned} 
$$

Sometimes, to simplify the notation, the numbers above and below the $\Sigma$ symbol are omitted. Likewise, the $i$ subscript is omitted. There is a general understanding that these components of the notation are omitted that the version of the notation above is implied.

$$
\begin{aligned} 
\sum{X} &= X_1 + X_2 + X_3\\ 
&= 110 + 120 + 100\\
&= 330
\end{aligned} 
$$


The full version of the notation can be used to indicate how a mean is calculated.


$$
\begin{aligned} 
\bar{X} &= \frac{\sum_{i=1}^{N} X_i}{N} \\
&= \frac{X_1 + X_2 + X_3}{3}\\ 
&= \frac{110 + 120 + 100}{3}\\
&= \frac{330}{3}\\
&= 110\\
\end{aligned} 
$$

Likewise, the concise version of the notation can be used to indicate how a mean is calculated.

$$
\begin{aligned} 
\bar{X} &= \frac{\sum{X}}{N} \\
&= \frac{X_1 + X_2 + X_3}{3}\\ 
&= \frac{110 + 120 + 100}{3}\\
&= \frac{330}{3}\\
&= 110\\
\end{aligned} 
$$

A common task in statistics is to calculate 1) the squared distance between each person and the mean, and 2) add up those squared differences. This calculation is easily expressed with the full version of the notation.

$$
\begin{aligned} 
\sum_{i=1}^{N}{(X_i - \bar{X})^2} &= (X_1-\bar{X})^2 + (X_2-\bar{X})^2 + (X_3-\bar{X})^2\\ 
&= (110-110)^2 + (120-110)^2 + (100-110)^2\\
&= (0)^2 + (10)^2 (-10)^2 \\
&= 0 + 100 + 100 \\
&= 200
\end{aligned} 
$$

Likewise, the sum of the squared deviations from the mean can be expressed using the concise version of the notation.

$$
\begin{aligned} 
\sum{(X - \bar{X})^2} &= (X_1-\bar{X})^2 + (X_2-\bar{X})^2 + (X_3-\bar{X})^2\\ 
&= (110-110)^2 + (120-110)^2 + (100-110)^2\\
&= (0)^2 + (10)^2 (-10)^2 \\
&= 0 + 100 + 100 \\
&= 200
\end{aligned} 
$$


## Population vs samples

As we move closer to conducting our own research it is critical to make a distinction between populations and samples. A populations is the complete set of people/animals about which we want to make conclusions. Samples are a subset of the total number of people/animals in the population. In most scenarios it is impractical to work with an entire population and, for practical reasons, we study a subset of the population called a sample. 

Researchers, and consumers of research, typically have little interest in making conclusions at the sample level. In general, we care about conclusions that generalize to the population not conclusions that only apply to specific individuals in the sample. Consider the case of COVID-19. Imagine a team of researchers creates a vaccine that they hope creates immunity to COVID-19. We care very little if the immunity only works for the specific individuals in the study. However, we care a great deal with if the immunity works, or is likely to work, for all Canadians or all humans. Thus, we study samples but typically wish to make conclusions that apply to the population.

Statistic tests are means of helping researchers use sample data to make conclusions at the population level. When we calculate numbers based on all of the people/animals in the population we refer to those numbers as **parameters**. We calculate numbers based on the people/animals in the sample we refer to those numbers as **statistics**. In general, statistics are used to estimate parameters. 

## A small population

Populations are typically quite large, but, for the purpose or reviewing how we typically describe populations we focus on a population of just three chocolate chip cookies. We refer to the three cookies as $X_1$, $X_2$, and $X_3$. The cookies have the weights of 8, 10, and 12 grams, respectively. 

### Mean

It can be helpful to create a model of our data such that each observation represents a deviation from a model describing the entire set of observations. That is we can think of our three cookies using the approach:

$$
\begin{aligned} 
X_i &= model + error_i \\
\end{aligned} 
$$



We can create a model for our data using many different approaches. A simple model for our data is the mean:

$$
\begin{aligned} 
\bar{X} &= \frac{\sum{X}}{N} \\
&= \frac{X_1 + X_2 + X_3}{3}\\ 
&= \frac{8 + 10 + 12}{3}\\
&= \frac{30}{3}\\
&= 10\\
\end{aligned} 
$$


Then we can think of this "mean cookie" our model as:

$$
\begin{aligned} 
X_i &= \bar{X} + error_i \\
\end{aligned} 
$$

The model, above is just concise way of describing the following:

$$
\begin{aligned} 
X_1 &= \bar{X} + error_1 \\
X_2 &= \bar{X} + error_2 \\
X_3 &= \bar{X} + error_3 \\
\end{aligned} 
$$

That is the weights of the three cookies ($X_1 = 8$, $X_2 = 10$, and $X_3 = 12$) can be conceptualized as:


$$
\begin{aligned} 
X_1 &= 10 + (-2) \\
X_2 &= 10 + 0 \\
X_3 &= 10 + 2 \\
\end{aligned} 
$$


The mean of the population, $\bar{X} = 10$, is a parameter that serves as model for the data. When we calculate a model for our data, it's helpful to have an index of how well the model fits the data. 

### Variance


Variance is a simple way of calculating how well the model fits our data. We can think of there being a conceptual "mean cookie" that describes our data. Then we want to see the extent to which the data differs from our "mean cookie" model.


```{r meancookie, echo=FALSE, out.width="60%", fig.cap="Variance as a fit index for the mean"}
knitr::include_graphics("ch_populations/images/cookie.png")
```



Variance is a simple approach to assessing the fit of the model. With this approach we determine the extent to which data point deviates from our model (our mean cookie), see Figure \@ref(fig:meancookie). The deviation between each data point and the model is referred to as error. 

Error, the extent to the data deviates from the model, is calculated using squared differences. That is, take each data point, subtract the model value, and then square the resulting number (e.g., $(8 - 10)^2 = 4$). It probably strikes you as an odd choice to square the difference between each data point and the model. Why not just take the difference (e.g., $(8 - 10) = -2$) or take the absolute difference (e.g., $|8 - 10|= 2$)? The answer is somewhat complex, but it relates to the more general situation in statistics of trying to find models that minimize error. When we use error as the squared difference it is easier to apply calculus, via derivatives, to calculate a model that minimizes the errors (i.e., obtains the best fit). Long story short, complex statistical reasons, we use squared differs to index error rather than other approaches.



| Cookie Mass |  Model | Error = Squared Difference | 
| ---         |  ---   |  ---             |
| $X_1 = 8$  |  $\bar{X} = 10$ |  $(X_1 - \bar{X})^2 =(8 - 10)^2= 4$ |
| $X_2 = 10$  |  $\bar{X} = 10$ |  $(X_2 - \bar{X})^2 =(10 - 10)^2= 0$ |
| $X_3 = 12$  |  $\bar{X} = 10$ |  $(X_3 - \bar{X})^2 =(12 - 10)^2= 4$ |

You can see in the table above that we can calculate the squared difference for data points 1 through 3. The squared differences are 4, 0, and 4, respectively. We combine these numbers into a single index by taking an average. This calculation, $(4 + 0 + 4)/3 = 2.67$, tell us the average of the squared deviations from the model is 2.67 grams$^2$. We refer to the this value as variance. 

Recall the formula for calculating an average:

$$
\begin{aligned} 
\bar{X} &= \frac{\sum{X}}{N} \\
\end{aligned} 
$$

You can see from the formula for variance below that variance is just an average. The average of the squared errors.

$$
\begin{aligned} 
var(X) &= \frac{\sum{(X - \bar{X})^2}}{N}\\
&= \frac{(X_1-\bar{X})^2 + (X_2-\bar{X})^2 + (X_3-\bar{X})^2}{N}  \\ 
&= \frac{(8-10)^2 + (10-10)^2 + (12-10)^2}{3}\\
&= \frac{(-2)^2 + (0)^2 (2)^2}{3} \\
&= \frac{4 + 0 + 4}{3} \\
&= \frac{8}{3} \\
&= 2.67 grams^2 \\
\end{aligned} 
$$


**Variance by any other name**. Variance is used in many places in inferential statistics. Unfortunately, it often goes by other name. Some of those names are listed below.

| Variance synonyms |
| - |
| Mean Squared Error |
| MSE |
| Pooled variance |
| $s_{pooled}^2$ |
| $s_{p}^2$ |
| $s_{residual}^2$ |



### Standard Deviation

Variance is easy to interpret as a the average of the squared differences between the model and the data. However, variance presents an answer in squared units (e.g., 2.67 grams$2$). Consequently, some people prefer to take the square root of this value and call it standard deviation.

$$
\begin{aligned} 
sd(X) &= \sqrt{var(X)} \\
&= \sqrt{2.67} \\
&= 1.63 grams\\
\end{aligned} 
$$

Unfortunately, although variance has a straight forward interpretation, standard deviation does not. Consider what happens when you take the square root of variance. Standard deviation can be thought of as the sum of the absolute deviations from the mean divided by the square root of the number of observations. Standard deviation is not an average - because you are dividing by the square root of N instead of just N. As a result, it's much harder to describe what standard deviation means.

$$
\begin{aligned} 
sd(X) &= \sqrt{\frac{\sum{(X - \bar{X})^2}}{N}}\\
 &= \frac{\sum{|X - \bar{X}|}}{\sqrt{N}}\\
\end{aligned} 
$$


We encourage you to think primarily in terms of variance rather than standard deviation due to the fact the interpretation of variance is more straightforward. Additionally, variance is foundational in the language used to describe regression and analysis of variance. That said, standard deviation is used in the calculation of some standardized effect sizes - so it is important to know and understand both indices.





```{r, include = FALSE}
library(learnSampling)
library(tidyverse)

# varible means, d-value of 0.5
hdata1 <- get_height_population(mdiff = 5, std = 10)
hdata1$sex <- as.factor(hdata1$sex)
hdata1$dvalue <- 0.5

# varible means, d-value of 1.0
hdata2 <- get_height_population(mdiff = 10, std = 10)
hdata2$sex <- as.factor(hdata2$sex)
hdata2$dvalue <- 1.0

# varible means, d-value of 2.0
hdata3 <- get_height_population(mdiff = 20, std = 10)
hdata3$sex <- as.factor(hdata3$sex)
hdata3$dvalue <- 2.0

textMean1 <- expression(Delta~"M" == 5)
textMean2 <- expression(Delta~"M" == 10)
textMean3 <- expression(Delta~"M" == 20)
textd1 <- expression(delta == 0.50)
textd2 <- expression(delta == 1.00)
textd3 <- expression(delta == 2.00)
textfemale1 <- expression("Female"~mu == 165)
textfemale2 <- expression("Female"~mu == 165)
textfemale3 <- expression("Female"~mu == 165)
textmale1 <- expression("Male"~mu == 170)
textmale2 <- expression("Male"~mu == 175)
textmale3 <- expression("Male"~mu == 185)
texts1 <- expression(sigma == 10)
texts2 <- expression(sigma == 10)
texts3 <- expression(sigma == 10)


g1 <- ggplot(data = hdata1,
       mapping = aes(x = height, linetype = sex)) +
  geom_density(position = "identity", alpha = .50, adjust = 2) +
  coord_cartesian(xlim = c(90, 250)) +
  scale_x_continuous(breaks = seq(90, 250, by = 10)) +
  annotate("text", x = 230, y = .03, 
           parse = T, label = as.character(textMean1)) +
  annotate("text", x = 230, y = .02, 
           parse = T, label = as.character(textd1)) +
  annotate("text", x = 90, y = .03, 
           parse = T, label = as.character(textfemale1), hjust = 0) +
  annotate("text", x = 90, y = .02, 
           parse = T, label = as.character(textmale1), hjust = 0) +
  annotate("text", x = 90, y = .01, 
           parse = T, label = as.character(texts1), hjust = 0) +
  theme_light() +
  labs(tag = "A.")

g2 <- ggplot(data = hdata2,
       mapping = aes(x = height, linetype = sex)) +
  geom_density(position = "identity", alpha = .50, adjust = 2) +
  coord_cartesian(xlim = c(90, 250)) +
  scale_x_continuous(breaks = seq(90, 250, by = 10)) +
  annotate("text", x = 230, y = .03, 
           parse = T, label = as.character(textMean2)) +
  annotate("text", x = 230, y = .02, 
           parse = T, label = as.character(textd2)) +
  annotate("text", x = 90, y = .03, 
           parse = T, label = as.character(textfemale2), hjust = 0) +
  annotate("text", x = 90, y = .02, 
           parse = T, label = as.character(textmale2), hjust = 0) +
  annotate("text", x = 90, y = .01, 
           parse = T, label = as.character(texts1), hjust = 0) +
  theme_light() +
  labs(tag = "B.")

g3 <- ggplot(data = hdata3,
       mapping = aes(x = height, linetype = sex)) +
  geom_density(position = "identity", alpha = .50, adjust = 2) +
  coord_cartesian(xlim = c(90, 250)) +
  scale_x_continuous(breaks = seq(90, 250, by = 10)) +
  annotate("text", x = 230, y = .03, 
           parse = T, label = as.character(textMean3)) +
  annotate("text", x = 230, y = .02, 
           parse = T, label = as.character(textd3)) +
  annotate("text", x = 90, y = .03, 
           parse = T, label = as.character(textfemale3), hjust = 0) +
  annotate("text", x = 90, y = .02, 
           parse = T, label = as.character(textmale3), hjust = 0) +
  annotate("text", x = 90, y = .01, 
           parse = T, label = as.character(texts1), hjust = 0) +
  theme_light() +
  labs(tag = "C.")

png(file = "ch_populations/images/dvalue_ex1.png", res = 300, width = 8*300, height = 8*300)
gridExtra::grid.arrange(g1, g2, g3, nrow =3)
dev.off()
```


```{r, include = FALSE}
library(learnSampling)
library(tidyverse)

# fixed means, d-value of 0.5
hdata1 <- get_height_population(std = 30)
hdata1$sex <- as.factor(hdata1$sex)
hdata1$dvalue <- 0.5

# fixed means, d-value of 1.0
hdata2 <- get_height_population(std = 15)
hdata2$sex <- as.factor(hdata2$sex)
hdata2$dvalue <- 1.0

# same means, d-value of 2.0
hdata3 <- get_height_population(std = 7.5)
hdata3$sex <- as.factor(hdata3$sex)
hdata3$dvalue <- 2.0

textMean1 <- expression(Delta~"M" == 15)
textMean2 <- expression(Delta~"M" == 15)
textMean3 <- expression(Delta~"M" == 15)
textd1 <- expression(delta == 0.50)
textd2 <- expression(delta == 1.00)
textd3 <- expression(delta == 2.00)
textfemale1 <- expression("Female"~mu == 165)
textfemale2 <- expression("Female"~mu == 165)
textfemale3 <- expression("Female"~mu == 165)
textmale1 <- expression("Male"~mu == 180)
textmale2 <- expression("Male"~mu == 180)
textmale3 <- expression("Male"~mu == 180)
texts1 <- expression(sigma == 30)
texts2 <- expression(sigma == 15)
texts3 <- expression(sigma == 7.5)


g1 <- ggplot(data = hdata1,
       mapping = aes(x = height, linetype = sex)) +
  geom_density(position = "identity", alpha = .50, adjust = 2) +
  coord_cartesian(xlim = c(90, 250)) +
  scale_x_continuous(breaks = seq(90, 250, by = 10)) +
  annotate("text", x = 230, y = .01, 
           parse = T, label = as.character(textMean1)) +
  annotate("text", x = 230, y = .0075, 
           parse = T, label = as.character(textd1)) +
  annotate("text", x = 90, y = .01, 
           parse = T, label = as.character(textfemale1), hjust = 0) +
  annotate("text", x = 90, y = .0075, 
           parse = T, label = as.character(textmale1), hjust = 0) +
  annotate("text", x = 90, y = .0050, 
           parse = T, label = as.character(texts1), hjust = 0) +
  theme_light() +
  labs(tag = "A.")

g2 <- ggplot(data = hdata2,
       mapping = aes(x = height, linetype = sex)) +
  geom_density(position = "identity", alpha = .50, adjust = 2) +
  coord_cartesian(xlim = c(90, 250)) +
  scale_x_continuous(breaks = seq(90, 250, by = 10)) +
  annotate("text", x = 230, y = .02, 
           parse = T, label = as.character(textMean2)) +
  annotate("text", x = 230, y = .015, 
           parse = T, label = as.character(textd2)) +
  annotate("text", x = 90, y = .02, 
           parse = T, label = as.character(textfemale2), hjust = 0) +
  annotate("text", x = 90, y = .015, 
           parse = T, label = as.character(textmale2), hjust = 0) +
  annotate("text", x = 90, y = .01, 
           parse = T, label = as.character(texts2), hjust = 0) +
  theme_light() +
  labs(tag = "B.")

g3 <- ggplot(data = hdata3,
       mapping = aes(x = height, linetype = sex)) +
  geom_density(position = "identity", alpha = .50, adjust = 2) +
  coord_cartesian(xlim = c(90, 250)) +
  scale_x_continuous(breaks = seq(90, 250, by = 10)) +
  annotate("text", x = 230, y = .04, 
           parse = T, label = as.character(textMean3)) +
  annotate("text", x = 230, y = .03, 
           parse = T, label = as.character(textd3)) +
  annotate("text", x = 90, y = .04, 
           parse = T, label = as.character(textfemale3), hjust = 0) +
  annotate("text", x = 90, y = .03, 
           parse = T, label = as.character(textmale3), hjust = 0) +
  annotate("text", x = 90, y = .02, 
           parse = T, label = as.character(texts3), hjust = 0) +
  theme_light() +
  labs(tag = "C.")

png(file = "ch_populations/images/dvalue_ex2.png", res = 300, width = 8*300, height = 8*300)
gridExtra::grid.arrange(g1, g2, g3, nrow =3)
dev.off()

```




```{r, include = FALSE}
library(learnSampling)
library(tidyverse)

# varible means, d-value of 1.0
hdata1 <- get_height_population(mdiff = 5, std = 5)
hdata1$sex <- as.factor(hdata1$sex)
hdata1$dvalue <- 1

# varible means, d-value of 1.0
hdata2 <- get_height_population(mdiff = 10, std = 10)
hdata2$sex <- as.factor(hdata2$sex)
hdata2$dvalue <- 1

# varible means, d-value of 2.0
hdata3 <- get_height_population(mdiff = 20, std = 20)
hdata3$sex <- as.factor(hdata3$sex)
hdata3$dvalue <- 1

textMean1 <- expression(Delta~"M" == "5 cm")
textMean2 <- expression(Delta~"M" == "10 cm")
textMean3 <- expression(Delta~"M" == "20 cm")
textd1 <- expression(delta == 1)
textd2 <- expression(delta == 1)
textd3 <- expression(delta == 1)
textfemale1 <- expression("Female"~mu == 165)
textfemale2 <- expression("Female"~mu == 165)
textfemale3 <- expression("Female"~mu == 165)
textmale1 <- expression("Male"~mu == 170)
textmale2 <- expression("Male"~mu == 175)
textmale3 <- expression("Male"~mu == 185)
texts1 <- expression(sigma == 5)
texts2 <- expression(sigma == 10)
texts3 <- expression(sigma == 20)


g1 <- ggplot(data = hdata1,
       mapping = aes(x = height, linetype = sex)) +
  geom_density(position = "identity", alpha = .50, adjust = 2) +
  coord_cartesian(xlim = c(90, 250)) +
  scale_x_continuous(breaks = seq(90, 250, by = 10)) +
  annotate("text", x = 230, y = .064, 
           parse = T, label = as.character(textMean1)) +
  annotate("text", x = 230, y = .048, 
           parse = T, label = as.character(textd1)) +
  annotate("text", x = 90, y = .064, 
           parse = T, label = as.character(textfemale1), hjust = 0) +
  annotate("text", x = 90, y = .048, 
           parse = T, label = as.character(textmale1), hjust = 0) +
  annotate("text", x = 90, y = .032, 
           parse = T, label = as.character(texts1), hjust = 0) +
  theme_light() +
  labs(tag = "A.")

g2 <- ggplot(data = hdata2,
       mapping = aes(x = height, linetype = sex)) +
  geom_density(position = "identity", alpha = .50, adjust = 2) +
  coord_cartesian(xlim = c(90, 250)) +
  scale_x_continuous(breaks = seq(90, 250, by = 10)) +
  annotate("text", x = 230, y = .032 , 
           parse = T, label = as.character(textMean2)) +
  annotate("text", x = 230, y = .024, 
           parse = T, label = as.character(textd2)) +
  annotate("text", x = 90, y = .032, 
           parse = T, label = as.character(textfemale2), hjust = 0) +
  annotate("text", x = 90, y = .024, 
           parse = T, label = as.character(textmale2), hjust = 0) +
  annotate("text", x = 90, y = .016, 
           parse = T, label = as.character(texts2), hjust = 0) +
  theme_light() +
  labs(tag = "B.")

g3 <- ggplot(data = hdata3,
       mapping = aes(x = height, linetype = sex)) +
  geom_density(position = "identity", alpha = .50, adjust = 2) +
  coord_cartesian(xlim = c(90, 250)) +
  scale_x_continuous(breaks = seq(90, 250, by = 10)) +
  annotate("text", x = 230, y = .016, 
           parse = T, label = as.character(textMean3)) +
  annotate("text", x = 230, y = .012, 
           parse = T, label = as.character(textd3)) +
  annotate("text", x = 90, y = .016, 
           parse = T, label = as.character(textfemale3), hjust = 0) +
  annotate("text", x = 90, y = .012, 
           parse = T, label = as.character(textmale3), hjust = 0) +
  annotate("text", x = 90, y = .008, 
           parse = T, label = as.character(texts3), hjust = 0) +
  theme_light() +
  labs(tag = "C.")

png(file = "ch_populations/images/dvalue_ex3.png", res = 300, width = 8*300, height = 8*300)
gridExtra::grid.arrange(g1, g2, g3, nrow =3)
dev.off()


```




```{r, include = FALSE}
library(learnSampling)
library(tidyverse)

# varible means, d-value of 0.5
hdata1 <- get_height_population(mdiff = 2, std = 10)
hdata1$sex <- as.factor(hdata1$sex)
hdata1$dvalue <- 0.5

# varible means, d-value of 1.0
hdata2 <- get_height_population(mdiff = 5, std = 10)
hdata2$sex <- as.factor(hdata2$sex)
hdata2$dvalue <- 1.0

# varible means, d-value of 2.0
hdata3 <- get_height_population(mdiff = 8, std = 10)
hdata3$sex <- as.factor(hdata3$sex)
hdata3$dvalue <- 2.0

textMean1 <- expression(Delta~"M" == 2)
textMean2 <- expression(Delta~"M" == 5)
textMean3 <- expression(Delta~"M" == 8)
textd1 <- expression(delta == 0.20)
textd2 <- expression(delta == 0.50)
textd3 <- expression(delta == 0.80)
textfemale1 <- expression("Female"~mu == 165)
textfemale2 <- expression("Female"~mu == 165)
textfemale3 <- expression("Female"~mu == 165)
textmale1 <- expression("Male"~mu == 167)
textmale2 <- expression("Male"~mu == 170)
textmale3 <- expression("Male"~mu == 173)
texts1 <- expression(sigma == 10)
texts2 <- expression(sigma == 10)
texts3 <- expression(sigma == 10)


g1 <- ggplot(data = hdata1,
       mapping = aes(x = height, linetype = sex)) +
  geom_density(position = "identity", alpha = .50, adjust = 2) +
  coord_cartesian(xlim = c(90, 250)) +
  scale_x_continuous(breaks = seq(90, 250, by = 10)) +
  annotate("text", x = 230, y = .03, 
           parse = T, label = as.character(textMean1)) +
  annotate("text", x = 230, y = .02, 
           parse = T, label = as.character(textd1)) +
  annotate("text", x = 90, y = .03, 
           parse = T, label = as.character(textfemale1), hjust = 0) +
  annotate("text", x = 90, y = .02, 
           parse = T, label = as.character(textmale1), hjust = 0) +
  annotate("text", x = 90, y = .01, 
           parse = T, label = as.character(texts2), hjust = 0) +
  theme_light() +
  labs(tag = "A.",subtitle = "'Small' effect")

g2 <- ggplot(data = hdata2,
       mapping = aes(x = height, linetype = sex)) +
  geom_density(position = "identity", alpha = .50, adjust = 2) +
  coord_cartesian(xlim = c(90, 250)) +
  scale_x_continuous(breaks = seq(90, 250, by = 10)) +
  annotate("text", x = 230, y = .03, 
           parse = T, label = as.character(textMean2)) +
  annotate("text", x = 230, y = .02, 
           parse = T, label = as.character(textd2)) +
  annotate("text", x = 90, y = .03, 
           parse = T, label = as.character(textfemale2), hjust = 0) +
  annotate("text", x = 90, y = .02, 
           parse = T, label = as.character(textmale2), hjust = 0) +
  annotate("text", x = 90, y = .01, 
           parse = T, label = as.character(texts2), hjust = 0) +
  theme_light() +
  labs(tag = "B.",subtitle = "'Medium' effect")

g3 <- ggplot(data = hdata3,
       mapping = aes(x = height, linetype = sex)) +
  geom_density(position = "identity", alpha = .50, adjust = 2) +
  coord_cartesian(xlim = c(90, 250)) +
  scale_x_continuous(breaks = seq(90, 250, by = 10)) +
  annotate("text", x = 230, y = .03, 
           parse = T, label = as.character(textMean3)) +
  annotate("text", x = 230, y = .02, 
           parse = T, label = as.character(textd3)) +
  annotate("text", x = 90, y = .03, 
           parse = T, label = as.character(textfemale3), hjust = 0) +
  annotate("text", x = 90, y = .02, 
           parse = T, label = as.character(textmale3), hjust = 0) +
  annotate("text", x = 90, y = .01, 
           parse = T, label = as.character(texts3), hjust = 0) +
  theme_light() +
  labs(tag = "C.",subtitle = "'Large' effect")

png(file = "ch_populations/images/dvalue_ex4.png", res = 300, width = 8*300, height = 8*300)
gridExtra::grid.arrange(g1, g2, g3, nrow =3)
dev.off()
```

## Comparing populations

Here is a bunch of text comparing population. For this text see Figure \@ref(fig:dex1).

```{r dex1, fig.cap="The difference between two population means can be expressed in the original units as indicated by $\\Delta M$. Alternatively, the difference can be expressed using a Standardized Mean Difference (SMD). The SMD index is also know as the population-level $d$-value and is represented by the symbol $\\delta$. The SMD is a way of expressing the difference between population means without using the original units. ", echo = FALSE, out.width="100%"}
knitr::include_graphics("ch_populations/images/dvalue_ex1.png")
```

Here is a bunch of text comparing population. For this text see Figure \@ref(fig:dex2).

```{r dex2, fig.cap="An advantage of using the Standardized Mean Difference (SMD) to index the difference between two population means (i.e., $\\delta$) is that it takes the population standard deviation into account. In these three examples, the difference between the populations means is the same using the original/raw units of centimeters. However, the standard deviation of the populations varies across scenarios A, B, and C. The SMD illustrates that these three scenarios are different. If you only looked the difference in the original units (i.e., $\\Delta M$) you would conclude the effect is the same across the three scenarios. However, by using SMD, indexed by $\\delta$ - the population $d$-value, you see that the effect is progressively stronger from scenario A, to B, to C. This is illustrated by the fact that there is progressively less overlap between the distributions as you move from scenario A to C.", echo = FALSE, out.width="100%"}
knitr::include_graphics("ch_populations/images/dvalue_ex2.png")
```


Here is a bunch of text comparing population. For this text see Figure \@ref(fig:dex3).

```{r dex3, fig.cap="The three scenarios in this figure illustrate that a Standardized Mean Difference (i.e., population $d$-value or $\\delta$) can remain constant across scenarios when there is a change in the raw difference (i.e., $\\Delta M$) between the population means. This constant SMD occurs because the standard deviations also changes across the three scenarios.", echo = FALSE, out.width="100%"}
knitr::include_graphics("ch_populations/images/dvalue_ex3.png")
```



```{r dex4, fig.cap="Cohen's (1988) effect size benchmarks.", echo = FALSE, out.width="100%"}
knitr::include_graphics("ch_populations/images/dvalue_ex4.png")
```


