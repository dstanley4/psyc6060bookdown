[
["making-your-data-ready-for-analysis.html", "Chapter 2 Making your data ready for analysis 2.1 Required Packages 2.2 Objective 2.3 Context 2.4 A mindset for moving foward", " Chapter 2 Making your data ready for analysis 2.1 Required Packages This chapter requires the following packages are installed: Required Packages apaTables janitor psych tidyverse Important Note: that you should NOT use library(psych) at any point. There are major conflict between the psych package and the tidyverse. We will access the psych package command by preceding each command with psych:: instead of using library(psych). 2.2 Objective 2.3 Context (Baker 2016) (Nosek 2015) A suprisingly common problem in science is that after an article is published, the authors can’t reproduce the numbers in the paper. You can read more about the important problem in a surprising article in the journal Molecular Brain. In this article an editor reports how a request for the data underlying articles resulted in the wrong data for 40 out of 41 papers (Miyakawa 2020). Long story short – keep track of the data and scripts you use for your paper. There is a growing interest in ensuring your analyses are reproducible. That is, that a third part could generate the numbers in the research article from materials provided by the researcher. Although this sounds like a low bar for rigor, it is in fact a surprisingly challening bar. Indeed, the editor of Molecular Brain. reported that a request for the data underlying articles resulted in the wrong data for 40 out of 41 papers. Consequently, a trend is for journals and authors to adopt Transparency and Openness Promotion (TOP) guidelines. These guidelines involve such things as making your materials, data, code, and analysis scripts available on public repositories so anyone can check your data. A new journal rating system even emerged call the TOP Factor. The idea is not that open science articles are not more trust worthy that other types of articles – the idea is that trust doesn’t play a role. Anyone can inspect the data using the scripts provided by authors. It’s really just the same as making your science available for auditing the way financial records can be audited. This process avoids the problem reported at Molecular Brain (doubless is common to many journals) - because the data and scripts need to have been uploaded at the time of publication. The TOP open science guidelines have made an impact and newer journals such as Meta Psycchology have fully embraced open science. Figure 2.1 shows the header from an article in Meta Psychology that clearly delineates the open science attributes of the article. Take note that the header even specifies who checked that the analyses in the article were reproducible. FIGURE 2.1: Open science in an article header 2.4 A mindset for moving foward FIGURE 2.2: Data science pipeline by Roger Peng. In this chapter we walk you though the process of going from raw data to analytic data by creating processing script. see Figure 2.2 References "],
["begin-with-the-end-in-mind.html", "Chapter 3 Begin with the end in mind", " Chapter 3 Begin with the end in mind -sample size analysis -unfalsible article by lakens TIDYVERSE NAMING CONVENTION ARE IMPORTANT BECAUSE IN SOME CASES THEY ARE REQUIRED for the SCRIPTS to work. If you haven’t following the naming conventions you may be making your life quite difficult. "],
["collecting-your-data.html", "Chapter 4 Collecting your data", " Chapter 4 Collecting your data data are collected in different ways data collected by programs in the lab that require lab measurementson paper and entering later paper surveys and entering later website surveys a mix of all of the above each trial is a row - multiple rows per person… Distinguish between entering data and not. But also think about what’s not confusing… talk about wide not showing DV or IV just levels of IV if you’re writing a cognitive program or making a survey think about the variable names think about how the data is outputed. If you have entirely within person data then tidy is the obvious choice If you have entirely between then wide makes sense If you have a mix - it’s more difficult. Different research area. Think about the problems. For example, a good data code book is essential if you have wide with repeated measures varibles because there is no way to tell what the IV or DV is by inspecting the data. "],
["entering-your-data.html", "Chapter 5 Entering your data", " Chapter 5 Entering your data "],
["making-analytic-data.html", "Chapter 6 Making analytic data", " Chapter 6 Making analytic data Think about - missing data - column names - representation of categorical variables in the data set "],
["entering-data.html", "Chapter 7 Entering data 7.1 Begin with a project 7.2 Raw data 7.3 Loading raw data 7.4 Initial inspection 7.5 Handling categorical variables 7.6 Seeing your data 7.7 Dealing with reverse key items 7.8 Creating the scale score 7.9 Creatinig analytic data from raw data 7.10 Wait: I need alpha! 7.11 Wait: I need item correlations and descriptive statistics 7.12 Using R the old way or the new way (the tidyverse way)", " Chapter 7 Entering data computer/web collection 7.1 Begin with a project I suggest you begin every R Studio task in the following way: R Studio in the Cloud 1. Create a new Project using the web interface 2. Upload your data files in using the upload button in the Files pane R Studio on Your Computer 1. Create a folder on your computer for the analysis 2. Place your data files in that folder 3. Use the menu item File &gt; New Project… to start the project 4. On the window that appears select “Existing Directory” 5. On the next screen, press the “Browse” button and find/select the folder with your data 6. Press the Create Project Button Regardless of whether your are working from the cloud or locally you should now have an R Studio project with your data files in it. Using Projects. Class note: You dont’ need to do either of these approach. You will just “Start” each assignment in the class workspace on R Studio Cloud\". 7.2 Raw data We begin by examining the data as originally entered into a spreadsheet. In Figure 7.1 you see a screen shot of the intial raw data as a researcher might receive it. Take careful note of the numerous -999 values used to indicate missing values. As part of creating the analytic data that we will analyze we need to indicate to the computer that the -999 are not data but codes to represent missing values. FIGURE 7.1: Raw data for item scoring 7.3 Loading raw data Create an RStudio project for this activity Create a new script in your project and save it wite library(tidyverse) library(janitor) ## ## Attaching package: &#39;janitor&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## chisq.test, fisher.test my_missing_value_codes &lt;- c(&quot;-999&quot;, &quot;&quot;, &quot;NA&quot;) raw_data &lt;- read_csv(file = &quot;data_item_scoring.csv&quot;, na = my_missing_value_codes) ## Parsed with column specification: ## cols( ## id = col_double(), ## age = col_double(), ## sex = col_character(), ## SE1 = col_double(), ## SE2 = col_double(), ## SE3 = col_double(), ## SE4 = col_double(), ## SE5 = col_double(), ## SE6 = col_double(), ## SE7 = col_double(), ## SE8 = col_double(), ## SE9 = col_double(), ## SE10 = col_double() ## ) 7.4 Initial inspection We use glimipse to do an initial inspection of the column names in this data set. All of the column name conform to tidyverse style guidelines so we do not need to run the clean_name() function from the janitor package glimpse(raw_data) ## Rows: 300 ## Columns: 13 ## $ id &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 1… ## $ age &lt;dbl&gt; 23, 22, 18, 23, 22, 17, 23, 22, 17, 21, 20, 17, 24, 17, 19, 19, … ## $ sex &lt;chr&gt; &quot;male&quot;, &quot;female&quot;, &quot;male&quot;, &quot;female&quot;, &quot;male&quot;, &quot;female&quot;, &quot;male&quot;, &quot;f… ## $ SE1 &lt;dbl&gt; 3, 4, 4, 3, 3, 3, 3, 4, 4, 4, 3, 4, NA, NA, 3, 3, 3, 3, 3, NA, 5… ## $ SE2 &lt;dbl&gt; 2, 3, 3, 2, 2, 3, 2, 3, 3, 3, 2, 2, NA, 3, 2, 2, 2, 2, 3, 2, 3, … ## $ SE3 &lt;dbl&gt; 4, 4, 4, 3, 4, 4, NA, 4, 4, 3, 4, 4, 4, NA, 4, NA, NA, 3, 4, 4, … ## $ SE4 &lt;dbl&gt; 3, 4, 4, 3, 4, 4, 4, 4, 3, 4, NA, 4, 3, 3, 4, NA, 3, 3, 4, 3, 4,… ## $ SE5 &lt;dbl&gt; 4, 4, 4, 4, 4, NA, NA, 4, 4, 4, 3, 4, 4, 3, 3, NA, 3, 3, NA, 4, … ## $ SE6 &lt;dbl&gt; 3, 5, 4, 3, 3, 3, 3, 5, 3, 3, 3, 4, 4, 3, 3, 4, 3, 3, 3, 3, 4, 3… ## $ SE7 &lt;dbl&gt; 1, 1, 1, NA, 1, 1, 2, 1, 2, 2, 3, 1, 3, 2, 1, 1, 2, 3, 1, 2, NA,… ## $ SE8 &lt;dbl&gt; 3, NA, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 2, 3, 3, 3, … ## $ SE9 &lt;dbl&gt; NA, 5, 5, 4, 4, 4, 4, 5, NA, 4, NA, 5, 4, 4, 4, 5, 4, 3, 4, 4, 5… ## $ SE10 &lt;dbl&gt; 5, NA, 5, 4, 5, 4, 4, 5, 5, 5, 4, NA, 4, 5, 4, 4, 4, 4, 5, 4, 5,… view(raw_data) See Figure 7.2 FIGURE 7.2: Missing values now NA 7.5 Handling categorical variables # Turn all columns that are of type character into factors raw_data &lt;- raw_data %&gt;% mutate(across(.cols = where(is.character), .fns = as.factor)) We can see there was only one column that changes, but if there had been many columns that were characters they all would have changed. glimpse(raw_data) ## Rows: 300 ## Columns: 13 ## $ id &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 1… ## $ age &lt;dbl&gt; 23, 22, 18, 23, 22, 17, 23, 22, 17, 21, 20, 17, 24, 17, 19, 19, … ## $ sex &lt;fct&gt; male, female, male, female, male, female, male, female, male, fe… ## $ SE1 &lt;dbl&gt; 3, 4, 4, 3, 3, 3, 3, 4, 4, 4, 3, 4, NA, NA, 3, 3, 3, 3, 3, NA, 5… ## $ SE2 &lt;dbl&gt; 2, 3, 3, 2, 2, 3, 2, 3, 3, 3, 2, 2, NA, 3, 2, 2, 2, 2, 3, 2, 3, … ## $ SE3 &lt;dbl&gt; 4, 4, 4, 3, 4, 4, NA, 4, 4, 3, 4, 4, 4, NA, 4, NA, NA, 3, 4, 4, … ## $ SE4 &lt;dbl&gt; 3, 4, 4, 3, 4, 4, 4, 4, 3, 4, NA, 4, 3, 3, 4, NA, 3, 3, 4, 3, 4,… ## $ SE5 &lt;dbl&gt; 4, 4, 4, 4, 4, NA, NA, 4, 4, 4, 3, 4, 4, 3, 3, NA, 3, 3, NA, 4, … ## $ SE6 &lt;dbl&gt; 3, 5, 4, 3, 3, 3, 3, 5, 3, 3, 3, 4, 4, 3, 3, 4, 3, 3, 3, 3, 4, 3… ## $ SE7 &lt;dbl&gt; 1, 1, 1, NA, 1, 1, 2, 1, 2, 2, 3, 1, 3, 2, 1, 1, 2, 3, 1, 2, NA,… ## $ SE8 &lt;dbl&gt; 3, NA, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 2, 3, 3, 3, … ## $ SE9 &lt;dbl&gt; NA, 5, 5, 4, 4, 4, 4, 5, NA, 4, NA, 5, 4, 4, 4, 5, 4, 3, 4, 4, 5… ## $ SE10 &lt;dbl&gt; 5, NA, 5, 4, 5, 4, 4, 5, 5, 5, 4, NA, 4, 5, 4, 4, 4, 4, 5, 4, 5,… It’s often helpful to has id as a factor rather than a number so we add and extra command that changes this value: raw_data &lt;-raw_data %&gt;% mutate(id = as.factor(id)) Now it looks like our data is ready for the creation of scale scores: glimpse(raw_data) ## Rows: 300 ## Columns: 13 ## $ id &lt;fct&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 1… ## $ age &lt;dbl&gt; 23, 22, 18, 23, 22, 17, 23, 22, 17, 21, 20, 17, 24, 17, 19, 19, … ## $ sex &lt;fct&gt; male, female, male, female, male, female, male, female, male, fe… ## $ SE1 &lt;dbl&gt; 3, 4, 4, 3, 3, 3, 3, 4, 4, 4, 3, 4, NA, NA, 3, 3, 3, 3, 3, NA, 5… ## $ SE2 &lt;dbl&gt; 2, 3, 3, 2, 2, 3, 2, 3, 3, 3, 2, 2, NA, 3, 2, 2, 2, 2, 3, 2, 3, … ## $ SE3 &lt;dbl&gt; 4, 4, 4, 3, 4, 4, NA, 4, 4, 3, 4, 4, 4, NA, 4, NA, NA, 3, 4, 4, … ## $ SE4 &lt;dbl&gt; 3, 4, 4, 3, 4, 4, 4, 4, 3, 4, NA, 4, 3, 3, 4, NA, 3, 3, 4, 3, 4,… ## $ SE5 &lt;dbl&gt; 4, 4, 4, 4, 4, NA, NA, 4, 4, 4, 3, 4, 4, 3, 3, NA, 3, 3, NA, 4, … ## $ SE6 &lt;dbl&gt; 3, 5, 4, 3, 3, 3, 3, 5, 3, 3, 3, 4, 4, 3, 3, 4, 3, 3, 3, 3, 4, 3… ## $ SE7 &lt;dbl&gt; 1, 1, 1, NA, 1, 1, 2, 1, 2, 2, 3, 1, 3, 2, 1, 1, 2, 3, 1, 2, NA,… ## $ SE8 &lt;dbl&gt; 3, NA, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 2, 3, 3, 3, … ## $ SE9 &lt;dbl&gt; NA, 5, 5, 4, 4, 4, 4, 5, NA, 4, NA, 5, 4, 4, 4, 5, 4, 3, 4, 4, 5… ## $ SE10 &lt;dbl&gt; 5, NA, 5, 4, 5, 4, 4, 5, 5, 5, 4, NA, 4, 5, 4, 4, 4, 4, 5, 4, 5,… 7.6 Seeing your data See the first six rows of the data with the head command below. If you wanted to see all of the data you would use View(raw_data). The NA values in the output indicate missing values (NA = Not Available). head(raw_data) ## # A tibble: 6 x 13 ## id age sex SE1 SE2 SE3 SE4 SE5 SE6 SE7 SE8 SE9 SE10 ## &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 23 male 3 2 4 3 4 3 1 3 NA 5 ## 2 2 22 female 4 3 4 4 4 5 1 NA 5 NA ## 3 3 18 male 4 3 4 4 4 4 1 3 5 5 ## 4 4 23 female 3 2 3 3 4 3 NA 3 4 4 ## 5 5 22 male 3 2 4 4 4 3 1 3 4 5 ## 6 6 17 female 3 3 4 4 NA 3 1 3 4 4 7.7 Dealing with reverse key items Our first step is dealing with reverse key items. The way you deal with these items depends on how you scored them. Imagine you had a 5-point scale. You could have scored the scale with the values 1, 2, 3, 4, and 5. Alternatively, you could have scored the scale with the values 0, 1, 2, 3, and 4. In this example, we scored the data using the 1 to 5 system. So we’ll use that. Later I’ll show you how to deal with the other scoring system (0 to 4). 7.7.1 Scoring items where the ratings scale starts with 1 We need to take items that were reversed-key when the participant wrote them and recode those responses. We do that with using the mutate command from the dplyr package. In this data file the only reverse-key item was SE7 (we known this from when we created the survey). We use the command below to reverse key an item with reponse options ranging from 1 to 5. So we use 6 in the command (i.e., one higher than 5). raw_data &lt;-raw_data %&gt;% mutate(SE7c = 6 - SE7) The command above creates a new column in raw_data called SE7c that has the reverse-keyed values for SE7 in it. You can see the new SE7c column using command below that displays the first six rows of the data. The SE7c column is at the far right of the data displayed. glimpse(raw_data) ## Rows: 300 ## Columns: 14 ## $ id &lt;fct&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 1… ## $ age &lt;dbl&gt; 23, 22, 18, 23, 22, 17, 23, 22, 17, 21, 20, 17, 24, 17, 19, 19, … ## $ sex &lt;fct&gt; male, female, male, female, male, female, male, female, male, fe… ## $ SE1 &lt;dbl&gt; 3, 4, 4, 3, 3, 3, 3, 4, 4, 4, 3, 4, NA, NA, 3, 3, 3, 3, 3, NA, 5… ## $ SE2 &lt;dbl&gt; 2, 3, 3, 2, 2, 3, 2, 3, 3, 3, 2, 2, NA, 3, 2, 2, 2, 2, 3, 2, 3, … ## $ SE3 &lt;dbl&gt; 4, 4, 4, 3, 4, 4, NA, 4, 4, 3, 4, 4, 4, NA, 4, NA, NA, 3, 4, 4, … ## $ SE4 &lt;dbl&gt; 3, 4, 4, 3, 4, 4, 4, 4, 3, 4, NA, 4, 3, 3, 4, NA, 3, 3, 4, 3, 4,… ## $ SE5 &lt;dbl&gt; 4, 4, 4, 4, 4, NA, NA, 4, 4, 4, 3, 4, 4, 3, 3, NA, 3, 3, NA, 4, … ## $ SE6 &lt;dbl&gt; 3, 5, 4, 3, 3, 3, 3, 5, 3, 3, 3, 4, 4, 3, 3, 4, 3, 3, 3, 3, 4, 3… ## $ SE7 &lt;dbl&gt; 1, 1, 1, NA, 1, 1, 2, 1, 2, 2, 3, 1, 3, 2, 1, 1, 2, 3, 1, 2, NA,… ## $ SE8 &lt;dbl&gt; 3, NA, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 2, 3, 3, 3, … ## $ SE9 &lt;dbl&gt; NA, 5, 5, 4, 4, 4, 4, 5, NA, 4, NA, 5, 4, 4, 4, 5, 4, 3, 4, 4, 5… ## $ SE10 &lt;dbl&gt; 5, NA, 5, 4, 5, 4, 4, 5, 5, 5, 4, NA, 4, 5, 4, 4, 4, 4, 5, 4, 5,… ## $ SE7c &lt;dbl&gt; 5, 5, 5, NA, 5, 5, 4, 5, 4, 4, 3, 5, 3, 4, 5, 5, 4, 3, 5, 4, NA,… We have reverse keyed one item. So now when we create our scale we will use item SE7c (the c stands for correctly coded) instead of the original item SE7. That is, we will use items SE1, SE2, SE3, SE4, SE5, SE6, SE7c, SE8, SE9, and SE10 to form the scale. Note for a box multiple items what it looks like Note FOR A BOX . If you had used response options numbered 0 to 4 for each item you would use the command below instead. Note that we use 4 in the command this time instead of a value one higher. raw_data &lt;- mutate(raw_data, SE7c = 4 - SE7) 7.8 Creating the scale score raw_data &lt;- raw_data %&gt;% rowwise() %&gt;% mutate(self_esteem = mean(c(SE1, SE2, SE3, SE4, SE5, SE6, SE7c, SE8, SE9, SE10), na.rm = TRUE)) %&gt;% ungroup() When you see ungroup() in ths context you can think of it as “turn off rowwise”. We can see our data now has the self esteem column: glimpse(raw_data) ## Rows: 300 ## Columns: 15 ## $ id &lt;fct&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17… ## $ age &lt;dbl&gt; 23, 22, 18, 23, 22, 17, 23, 22, 17, 21, 20, 17, 24, 17, 1… ## $ sex &lt;fct&gt; male, female, male, female, male, female, male, female, m… ## $ SE1 &lt;dbl&gt; 3, 4, 4, 3, 3, 3, 3, 4, 4, 4, 3, 4, NA, NA, 3, 3, 3, 3, 3… ## $ SE2 &lt;dbl&gt; 2, 3, 3, 2, 2, 3, 2, 3, 3, 3, 2, 2, NA, 3, 2, 2, 2, 2, 3,… ## $ SE3 &lt;dbl&gt; 4, 4, 4, 3, 4, 4, NA, 4, 4, 3, 4, 4, 4, NA, 4, NA, NA, 3,… ## $ SE4 &lt;dbl&gt; 3, 4, 4, 3, 4, 4, 4, 4, 3, 4, NA, 4, 3, 3, 4, NA, 3, 3, 4… ## $ SE5 &lt;dbl&gt; 4, 4, 4, 4, 4, NA, NA, 4, 4, 4, 3, 4, 4, 3, 3, NA, 3, 3, … ## $ SE6 &lt;dbl&gt; 3, 5, 4, 3, 3, 3, 3, 5, 3, 3, 3, 4, 4, 3, 3, 4, 3, 3, 3, … ## $ SE7 &lt;dbl&gt; 1, 1, 1, NA, 1, 1, 2, 1, 2, 2, 3, 1, 3, 2, 1, 1, 2, 3, 1,… ## $ SE8 &lt;dbl&gt; 3, NA, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 2, 3,… ## $ SE9 &lt;dbl&gt; NA, 5, 5, 4, 4, 4, 4, 5, NA, 4, NA, 5, 4, 4, 4, 5, 4, 3, … ## $ SE10 &lt;dbl&gt; 5, NA, 5, 4, 5, 4, 4, 5, 5, 5, 4, NA, 4, 5, 4, 4, 4, 4, 5… ## $ SE7c &lt;dbl&gt; 5, 5, 5, NA, 5, 5, 4, 5, 4, 4, 3, 5, 3, 4, 5, 5, 4, 3, 5,… ## $ self_esteem &lt;dbl&gt; 3.555556, 4.250000, 4.100000, 3.222222, 3.700000, 3.66666… (Alternative code: removing ITEM 7 and using begings with: show full example) Think about this when creating names for your column 7.9 Creatinig analytic data from raw data Select only the columns you will use in your analysis: analytic_data &lt;- raw_data %&gt;% select(id, age, sex, self_esteem) We can see our new data set has only these columns of interest: glimpse(analytic_data) ## Rows: 300 ## Columns: 4 ## $ id &lt;fct&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17… ## $ age &lt;dbl&gt; 23, 22, 18, 23, 22, 17, 23, 22, 17, 21, 20, 17, 24, 17, 1… ## $ sex &lt;fct&gt; male, female, male, female, male, female, male, female, m… ## $ self_esteem &lt;dbl&gt; 3.555556, 4.250000, 4.100000, 3.222222, 3.700000, 3.66666… 7.10 Wait: I need alpha! We return to the raw_data file that has the original item data to obtain Cronbach’s alpha which is labeled “raw alpha” in the output. self_esteem_item_analysis &lt;- raw_data %&gt;% select(SE1, SE2, SE3, SE4, SE5, SE6, SE7c, SE8, SE9, SE10) %&gt;% psych::alpha() print(self_esteem_item_analysis$total) ## raw_alpha std.alpha G6(smc) average_r S/N ase mean sd ## 0.82784 0.8333164 0.8276437 0.3333062 4.999389 0.0142959 3.65607 0.3391688 ## median_r ## 0.3277105 # To see the full item analysis use: # print(self_esteem_item_analysis) 7.11 Wait: I need item correlations and descriptive statistics SE_items &lt;- raw_data %&gt;% select(starts_with(&quot;SE&quot;, ignore.case = FALSE)) psych::describe(SE_items) ## vars n mean sd median ## SE1 1 276 3.39 0.54 3 ## SE2 2 272 2.35 0.48 2 ## SE3 3 269 3.96 0.37 4 ## SE4 4 285 3.54 0.50 4 ## SE5 5 265 3.78 0.47 4 ## SE6 6 275 3.34 0.51 3 ## SE7 7 273 1.51 0.61 1 ## SE8 8 272 2.84 0.37 3 ## SE9 9 265 4.29 0.70 4 ## SE10 10 276 4.57 0.61 5 ## SE7c 11 273 4.49 0.61 5 When you run the cor command you have to indicate how the it will handle missing the data. The options are below. You can learn more about what each one of these options means by typing: ?cor into the Console, this will bring up the help page for the cor command. Missing data options for cor everything all.obs complete.obs na.or.complete pairwise.complete.obs SE_items %&gt;% cor(use = &quot;pairwise.complete.obs&quot;) %&gt;% round(2) ## SE1 SE2 SE3 SE4 SE5 SE6 SE7 SE8 SE9 SE10 SE7c ## SE1 1.00 0.31 0.20 0.34 0.34 0.33 -0.32 0.28 0.38 0.31 0.32 ## SE2 0.31 1.00 0.24 0.22 0.31 0.32 -0.29 0.29 0.36 0.34 0.29 ## SE3 0.20 0.24 1.00 0.28 0.30 0.23 -0.43 0.38 0.35 0.28 0.43 ## SE4 0.34 0.22 0.28 1.00 0.29 0.34 -0.37 0.32 0.32 0.19 0.37 ## SE5 0.34 0.31 0.30 0.29 1.00 0.39 -0.41 0.41 0.43 0.40 0.41 ## SE6 0.33 0.32 0.23 0.34 0.39 1.00 -0.32 0.24 0.34 0.25 0.32 ## SE7 -0.32 -0.29 -0.43 -0.37 -0.41 -0.32 1.00 -0.44 -0.42 -0.39 -1.00 ## SE8 0.28 0.29 0.38 0.32 0.41 0.24 -0.44 1.00 0.51 0.35 0.44 ## SE9 0.38 0.36 0.35 0.32 0.43 0.34 -0.42 0.51 1.00 0.36 0.42 ## SE10 0.31 0.34 0.28 0.19 0.40 0.25 -0.39 0.35 0.36 1.00 0.39 ## SE7c 0.32 0.29 0.43 0.37 0.41 0.32 -1.00 0.44 0.42 0.39 1.00 7.12 Using R the old way or the new way (the tidyverse way) Previously we noted that there is an older way of using R (base R) and the new way of using R (the tidyverse) that we will use. Sometimes students have problems with their code when they mix and match these appoaches using a bit of both. We will be using the tidyverse approach to using R but on the internet you will often see sample code that uses the older base R approach. A bit of background knowledge is helpful for understanding why we do things one way (e.g., read_csv with the tidyverse) instead of another (e.g., read.csv with base R). 7.12.0.1 Tibbles vs Data Frames: Why use read_csv instead of read.csv When you load data into R it is typically represented in one of two formats inside the computer - depending on the command you used. The original format for representing a data set in R is the data frame. You will see this term used frequently when you read about R. When you load data using read.csv your data is loaded into a data frame in the computer. That is your data is represented in the memory of the computer in particular format and structure called a data frame. 7.12.0.2 read.csv puts data into a data frame my_dataframe &lt;- read.csv(file = &quot;data_okcupid.csv&quot;) Notice that when you print a data frame it does NOT show you the number of rows or columns above the data like our example did with the okcupid_profiles data. It also list ALL of your data rather than just the first few rows. As a result in the output below I show only the first 10 rows of the output - because all the rows are printed in your Console (too much to show here). print(my_dataframe) ## age diet height pets sex status ## 1 22 strictly anything 75 likes dogs and likes cats m single ## 2 35 mostly other 70 likes dogs and likes cats m single ## 3 38 anything 68 has cats m available ## 4 23 vegetarian 71 likes cats m single ## 5 29 &lt;NA&gt; 66 likes dogs and likes cats m single ## 6 29 mostly anything 67 likes cats m single ## 7 32 strictly anything 65 likes dogs and likes cats f single ## 8 31 mostly anything 65 likes dogs and likes cats f single ## 9 24 strictly anything 67 likes dogs and likes cats f single ## 10 37 mostly anything 65 likes dogs and likes cats m single 7.12.0.3 read_csv puts data into a tibble When you use the read_csv command the data you load is stored in the computer as a tibble. The tibble is modern version of the data frame. Notice that when you print a tibble it DOES show you the number of rows and columns. As well, the tibble only provides the first few rows of output so it doesn’t fill your screen. my_tibble &lt;- read_csv(file = &quot;data_okcupid.csv&quot;) ## Parsed with column specification: ## cols( ## age = col_double(), ## diet = col_character(), ## height = col_double(), ## pets = col_character(), ## sex = col_character(), ## status = col_character() ## ) print(my_tibble) ## # A tibble: 59,946 x 6 ## age diet height pets sex status ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 22 strictly anything 75 likes dogs and likes cats m single ## 2 35 mostly other 70 likes dogs and likes cats m single ## 3 38 anything 68 has cats m available ## 4 23 vegetarian 71 likes cats m single ## 5 29 &lt;NA&gt; 66 likes dogs and likes cats m single ## 6 29 mostly anything 67 likes cats m single ## 7 32 strictly anything 65 likes dogs and likes cats f single ## 8 31 mostly anything 65 likes dogs and likes cats f single ## 9 24 strictly anything 67 likes dogs and likes cats f single ## 10 37 mostly anything 65 likes dogs and likes cats m single ## # … with 59,936 more rows 7.12.0.4 Deeper differences between data frames and tibbles In short you should always use tibbles (i.e., use read_csv) - they are simply enhanced data frames (i.e., the new version of the data frame). The differences between data frames and tibbles run deeper than the superficial output provided here. On some rare occasions an old package or command may not work with a tibble so you need to make it a data frame. You can do so with the commands below: 7.12.0.5 Converting a tibble into a data frame This command creates a new data set called new_data_frame (use any name you want) from the tibble data. new_dataframe &lt;- as.data.frame(my_tibble) "]
]
