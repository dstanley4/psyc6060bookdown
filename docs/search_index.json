[
["samples.html", "Chapter 5 Samples 5.1 Data for the chapter 5.2 Notation 5.3 Estimating the mean 5.4 Estimating variance 5.5 Estimating standard deviation 5.6 Estimating SMD 5.7 Bias 5.8 Meta-analysis 5.9 Overview", " Chapter 5 Samples Researchers are usually interested in describing the attributes of a population; numbers that describe the population are called parameters. Two parameters that are frequently of interest are the mean and variance of the population. Unfortunately, it’s rarely possible to obtain information from every member of a population to calculate a parameter. Consequently, researchers use subsets of the population called samples to estimate parameters. Numbers calculated from sample data are called statistics. Typically, sample statistics are used to estimate population parameters. Sample statistics, however, often differ from population parameters. The difference between a sample statistic and the population parameter occurs because the sample data is random subset of the population data — with correspondingly fewer observations. Sometimes the sample statistic will be higher than the population parameter; other times the sample statistic will be lower than the population parameter. Because random sampling is used to select the sample data the direction and magnitude of the difference between the sample statistic the population parameter will vary randomly. Further complicating matters is the fact that the formula used for a sample statistic may or may not be the same as the formula used for the corresponding population parameter. This occurs because the purpose of the sample statistic is typically not to describe the sample. Rather the purpose of the sample statistic is to estimate the population parameter. Depending on the parameter, you may or may not be able to use the same formula with sample data as you would with population data. 5.1 Data for the chapter We begin by activating the required packages: library(tidyverse) library(learnSampling) Next, we create a large population with 100,000 people using the get_height_population() command: pop_data &lt;- get_height_population() The glimpse() command can be used to confirm that the population contains 100,000 people. glimpse(pop_data) ## Rows: 100,000 ## Columns: 3 ## $ id &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18,… ## $ sex &lt;chr&gt; &quot;male&quot;, &quot;female&quot;, &quot;female&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;female&quot;, … ## $ height &lt;dbl&gt; 177, 150, 171, 157, 169, 187, 163, 173, 172, 193, 190, 181, 15… We can use the head() command to see the first 10 rows of the 100,00 rows. We see that each row in pop_data represents a single person. head(pop_data, 10) ## # A tibble: 10 x 3 ## id sex height ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 male 177 ## 2 2 female 150 ## 3 3 female 171 ## 4 4 male 157 ## 5 5 male 169 ## 6 6 male 187 ## 7 7 female 163 ## 8 8 male 173 ## 9 9 female 172 ## 10 10 male 193 5.2 Notation In the formulas below, when we refer the population, we use uppercase letters when indicating members (\\(X\\)) or the size (\\(N\\)). In contrast, when we refer to the sample, we use lowercsae letters when indicating members (\\(x\\)) or the size (\\(n\\)). Make sure you notice the similarities between population and sample formulas even when the notation differs. 5.3 Estimating the mean We are interested in the sample mean (\\(\\bar{x}\\)) to the extent that it provides an estimate of the population mean (\\(\\mu\\)). The population mean is calculated using Formula (5.1): \\[\\begin{equation} \\mu = \\frac{\\sum{X}}{N} \\tag{5.1} \\end{equation}\\] We can calculate the population mean for the height column of pop_data using the summarise() and mean() commands. The mean() command uses Formula (5.1). We see in the output that the population mean is 172.48 (\\(\\mu = 172.48\\)). pop_data %&gt;% summarise(pop_mean = mean(height)) %&gt;% as.data.frame() ## pop_mean ## 1 172.4762 As noted previously, we rarely has access to data from an entire population. Consequently, we use the sample mean as an estimate of the population mean. The sample mean, \\(\\bar{x}\\), is a statistic calculated using the using Formula (5.2). The bar of above the \\(x\\), indicates that it is a mean. Notice that Formula (5.1) and Formula (5.2) are the same - even though they use different notation. \\[\\begin{equation} \\bar{x} = \\frac{\\sum{x}}{n} \\tag{5.2} \\end{equation}\\] Because a sample mean (a statistic) is calculated using a random subset of the population it is likely to differ from the population mean (a parameter). If you, inaccurately, believe that you can learn something meaningful from a single study, this fact may be concerning. Statisticians know, however, that you can rarely learn anything from a single study or even a small set of studies. Consequently, they are more interested in what is true, on average, over a large number of studies. Therefore, we simulate drawing a large number of samples from a population with the code below. many_samples &lt;- get_M_samples(pop.data = pop_data, pop.column.name = height, n = 10, number.of.samples = 5000) We use the head() command to see the first 10 rows (i.e., 10 samples of 5000 samples): head(many_samples, 10) ## study n sample.mean sample.var.n sample.var.n_1 ## 1 1 10 174.3 27.810 30.90 ## 2 2 10 161.8 83.358 92.62 ## 3 3 10 173.2 139.158 154.62 ## 4 4 10 180.0 321.804 357.56 ## 5 5 10 172.8 160.956 178.84 ## 6 6 10 172.0 159.597 177.33 ## 7 7 10 166.5 86.454 96.06 ## 8 8 10 173.5 139.446 154.94 ## 9 9 10 177.7 167.013 185.57 ## 10 10 10 168.5 262.647 291.83 Each row of many_samples represents a sample of 10 people. Each column of many_samples indicates a sample statistic. You can see the for each sample/row we indicate n (the sample size) and sample.mean (the mean of the population), and a few other statistics. Even though all the samples came from the same population you can see how the values in the sample.mean column vary across samples/rows. You can see the full extent to which the sample means vary by creating a graph with the code below. In this code, we use the pull() command to extract the value from the sample.mean column and then we send them to the base R hisogram command, hist(). many_samples %&gt;% pull(sample.mean) %&gt;% hist(main = &quot;Histogram of Sample Means&quot;) You can see the 5000 sample means, from the sample.mean column, plotted in this graph. Recall the population mean for heights is \\(\\mu = 172.48\\) cm. Notice that most of the sample means cluster around this value. Also notice there is considerable variability about this value. Any given sample mean (\\(\\bar{x}\\)) may differ substantially from the population mean (\\(\\mu = 172.48\\)). This variability illustrates the challenges with learning something from a single study - particularly a study with a small sample size. Many of the sample means fall quite far from the population mean. Statisticians, recognizing the limitations of a single study, are not particularly concerned if a single sample mean deviates from the population mean. That said, statisticians are very concerned whether the results of a large number of studies are correct – on average. That is, does the average of many sample means correspond to the population mean. If, on average, the sample mean is accurate we refer to it as an unbiased estimator. In the code below we calculate the average of the 5000 sample means to determine if the sample mean is an unbiased estimator. many_samples %&gt;% summarise(mean_of_sample.mean = mean(sample.mean)) %&gt;% as.data.frame() ## mean_of_sample.mean ## 1 172.4078 We find that the average of the 5000 sample means is 172.41 which is very close to the population mean of 172.48. Note that when we did this, we used the same formula to calculate the sample mean (Formula (5.2)) as we did the population mean (Formula (5.1)), although the notation differed. The average of the sample means was not identical to the population mean but it was very close - it would have been exactly the same with many more samples. Consequently, the sample mean provides an unbiased estimate of the population mean. In other words, it makes sense to use the sample mean as an estimate of the population mean. If we try to estimate the population mean with a sample mean we will, on average, be correct; although any given sample/study mean might be “wrong”. 5.4 Estimating variance We are interested in the sample variance (\\(s^2\\)) to the extent that it provides an estimate of the population variance (\\(\\sigma^2\\)). The population variance is calculated using Formula (5.3): \\[\\begin{equation} \\sigma^2 = \\frac{\\sum{(X - \\mu)^2}}{N} \\tag{5.3} \\end{equation}\\] We can calculate the population variance for the height column of pop_data using the summarise() and var.pop() commands. The var.pop() command uses Formula (5.3). We see in the output that the population variance is 157.5 (\\(\\sigma^2 = 157.5\\)). pop_data %&gt;% summarise(pop_var = var.pop(height)) %&gt;% as.data.frame() ## pop_var ## 1 157.4611 Because we rarely have access to data for an entire population we typically want to estimate the population variance using sample data. However, estimating the population parameter from a statistic, is more complicated for variance than it was for the mean. Initially, we might be tempted to use the formula below for sample variance, in which we divide by \\(n\\). This formula is the same as the population variance formula, Formula (5.3), but adapted to use sample-level notation. \\[ \\begin{aligned} s^2 = \\frac{\\sum{(x - \\bar{x})^2}}{n} \\end{aligned} \\] The formula for sample variance with an \\(n\\) in the denominator is, unfortunately, a biased estimator of population variance. In the many_samples data, the column sample.var.n contains the variance for the sample calculated with the above formula. Below we use code to obtain the average of the sample.var.n column over the 5000 samples. If this average equals the population variance of 157.5 then variance, using \\(n\\) in the denominator, is an unbiased estimator of the population variance. many_samples %&gt;% summarise(mean_of_var.n = mean(sample.var.n)) %&gt;% as.data.frame() ## mean_of_var.n ## 1 141.0726 The average of sample.var.n column (141.86) was much smaller than the population variance (157.5). That is, the average of the sample variances, using \\(n\\) in the denominator, was smaller than the population variance. Consequently, sample variance, using \\(n\\) in the denominator, provides a biased estimate of the population variance. If we try to estimate the population variance with sample variance, using \\(n\\) in the denominator, we will, on average, be wrong. Fortunately, there is a sample-level formula that estimates the population variance without bias (see Hayes). An unbiased estimate of the population variance can be obtained if we calculate the sample variance but divide by \\(n - 1\\) instead of \\(n\\). The unbiased estimate is calculated using Formula (5.4). \\[\\begin{equation} s^2 = \\frac{\\sum{(x - \\bar{x})^2}}{n-1} \\tag{5.4} \\end{equation}\\] In the many_samples data, the column sample.var.n_1 was generated using Formula (5.4). We can evaluate the quality of Formula (5.4), using \\(n-1\\), by averaging over values in the sample.var.n_1 column. many_samples %&gt;% summarise(mean_of_var.n_1 = mean(sample.var.n_1)) %&gt;% as.data.frame() ## mean_of_var.n_1 ## 1 156.7474 We see that the average of the 5000 values using \\(n-1\\) in the denominator is 157.62 which is very close to the population varaince of 157.46. Consequently, we when we use \\(n-1\\) in the denominator we have an unbiased estimate of the population variance. If we try to estimate the population variance with a sample variance, using \\(n-1\\) in the denominator, we will, on average, be right. You may wonder at this point, when we use \\(n-1\\) in the denominator of the sample variance, can we still think of it as the average of the squared deviations from the mean. The short answer is yes. When you use \\(n-1\\) in the denominator of the sample variance you are not calculating the variance for the group people in the sample. Rather, you are estimating the variance for the much larger group of people in the population. Consequently, it makes sense to think of sample variance, using \\(n-1\\), as an estimate of the average of the squared errors in the population. That is, it makes sense to think of sample variance, using \\(n-1\\), as an estimate of the average of the squared differences between each person in the population and the population mean. 5.5 Estimating standard deviation Due to the above findings for variance, we tend to estimate the population standard deviation using Formula (5.5). \\[\\begin{equation} s = \\sqrt{\\frac{\\sum{(x - \\bar{x})^2}}{n-1}} \\tag{5.5} \\end{equation}\\] 5.6 Estimating SMD So far we have considered people’s heights as a single population. You may have noticed, however, that we have column indicating the sex of each person. Consequently, we could think of there being two populations - a population of heights of males and a population of heights for females. When you have two populations often it is desirable to express the differences between the two populations as a standardized mean difference (SMD) also known as Cohen’s \\(d\\). We begin be determining the mean and standard deviation of each population with the code below: pop_data %&gt;% group_by(sex) %&gt;% summarise(mean = mean(height), sd = sd.pop(height)) %&gt;% as.data.frame() ## `summarise()` ungrouping output (override with `.groups` argument) ## sex mean sd ## 1 female 164.9762 10.06037 ## 2 male 179.9762 10.06037 From this output we see the population parameters for males and females. The mean of the male population heights is 180 (\\(\\mu_{male} = 180\\)) whereas the mean of the female population heights is 165 (\\(\\mu_{male} = 165\\)). Both populations have a standard deviation of 10.1 (\\(\\sigma = \\sigma_{female} = \\sigma_{male} = 10.1\\)): \\[ \\begin{aligned} \\mu_{female} &amp;= 165 \\\\ \\mu_{male} &amp;= 180 \\\\ \\sigma = \\sigma_{female} = \\sigma_{male} &amp;= 10.1\\\\ \\end{aligned} \\] 5.6.1 Population SMD The population-level standardized mean difference (i.e., Cohen’s \\(d\\) or \\(\\delta\\)) is calculated using Formula (5.6). \\[\\begin{equation} \\delta = \\frac{\\mu_{1} - \\mu_{2}}{\\sigma} \\tag{5.6} \\end{equation}\\] We use the previously obtained population parameters in Formula (5.6) and find that the standardized mean difference is 1.49 (i.e., \\(\\delta = 1.49\\)). This population-level difference is illustrated in Figure 5.1. \\[ \\begin{aligned} \\delta &amp;= \\frac{\\mu_{male} - \\mu_{female}}{\\sigma} \\\\ &amp;= \\frac{180 - 165}{10.1} \\\\ &amp;= \\frac{15}{10.1} \\\\ &amp;= 1.49 \\\\ \\end{aligned} \\] FIGURE 5.1: Illustration of the standardized mean difference of 1.49 for height between males and females. The solid black vertical lines indicates the means (\\(\\mu\\)) for the two populations. 5.6.2 Sample SMD When calculating the standardized mean difference we rarely have access to the entire population. Consequently, we need to estimate the population-level standardized mean difference using sample data. The sample-level approach to calculating SMD is presented below in Formula (5.7). This value is known by many other names: \\(d\\), Cohen’s \\(d\\), and Hedges \\(g\\). \\[\\begin{equation} d = \\frac{\\bar{x}_{1} - \\bar{x}_{2}}{s_{pooled}} \\tag{5.7} \\end{equation}\\] \\[\\begin{equation} d_{unbiased} = \\frac{\\bar{x}_{1} - \\bar{x}_{2}}{s_{pooled}} \\times [1 - \\frac{3}{4(n_1 + n_2)-9}] \\tag{5.8} \\end{equation}\\] \\[ \\begin{aligned} d_{unbiased} &amp;= d \\times [1 - \\frac{3}{4(n_1 + n_2)-9}] \\\\ \\end{aligned} \\] A notable difference 5.6.2.1 Estimating means 5.6.2.2 Estimating variance \\[\\begin{equation} s_{pooled}^2 = \\frac{(n_1 -1)s_1^2 + (n_2 -1)s_2^2}{n_1 + n_2-2} \\tag{5.9} \\end{equation}\\] \\[\\begin{equation} s_{pooled}^2 = \\frac{s_{1}^2 + s_{2}^2}{2} \\tag{5.10} \\end{equation}\\] \\[ \\begin{aligned} s_{pooled}^2 &amp;= \\frac{s_{male}^2 + s_{female}^2}{2} \\\\ \\end{aligned} \\] FIGURE 5.2: The male sample variance (n-1) is an estimate of male population variance. Likewise, the female sample variance (n-1) is an estimate of the female population variance. FIGURE 5.3: We assume the population variances are the same. Therefore, the male and female sample variances are both estimates of the same population variance. FIGURE 5.4: We create a single estimate of the population variance called pooled variance (\\(s_{pooled}^2\\)). When sample sizes are equal, the pooled variance is just the average of the two sample variances (both using n-1). When the sample sizes are unequal (i.e., different numbers of males and females), we need to use a more sophisticated formula to obtain the pooled variance. 5.6.2.3 Combining everything \\[ \\begin{aligned} d &amp;= \\frac{\\bar{x}_{male} - \\bar{x}_{female}}{s_{pooled}} \\\\ \\end{aligned} \\] \\[ \\begin{aligned} d_{unbiased} &amp;= d \\times [1 - \\frac{3}{4(n_1 + n_2)-9}] \\\\ \\end{aligned} \\] 5.7 Bias male_population_heights &lt;- pop_data %&gt;% filter(sex == &quot;male&quot;) %&gt;% pull(height) female_population_heights &lt;- pop_data %&gt;% filter(sex == &quot;female&quot;) %&gt;% pull(height) many_samples&lt;- get_d_samples_from_population_data(pop1 = male_population_heights, pop2 = female_population_heights, cell.n = 10, number.of.samples = 5000) head(many_samples, 10) ## study cell1.n cell2.n sample.d sample.d.unbiased ## 1 1 10 10 2.6121144 2.5017434 ## 2 2 10 10 1.3754606 1.3173426 ## 3 3 10 10 1.5562944 1.4905355 ## 4 4 10 10 1.1478714 1.0993698 ## 5 5 10 10 1.9674666 1.8843342 ## 6 6 10 10 1.1227429 1.0753031 ## 7 7 10 10 1.3710610 1.3131288 ## 8 8 10 10 0.9633268 0.9226229 ## 9 9 10 10 1.9396292 1.8576730 ## 10 10 10 10 0.4242523 0.4063261 many_samples %&gt;% summarise(mean_of_d = mean(sample.d)) %&gt;% as.data.frame() ## mean_of_d ## 1 1.550115 many_samples %&gt;% summarise(mean_of_d_unbiased = mean(sample.d.unbiased)) %&gt;% as.data.frame() ## mean_of_d_unbiased ## 1 1.484617 5.8 Meta-analysis 5.9 Overview Name Parameter Estimated by this statistic Mean \\(\\mu = \\frac{\\sum{X}}{N}\\) \\(\\bar{x} = \\frac{\\sum{x}}{n}\\) Variance \\(\\sigma^2 = \\frac{\\sum{(X - \\mu)^2}}{N}\\) \\(s^2 = \\frac{\\sum{(x - \\bar{x})^2}}{n-1}\\) \\(s_{pooled}^2 = \\frac{(n_1 -1)s_1^2 + (n_2 -1)s_2^2}{n_1 + n_2-2}\\) \\(MSE = \\frac{(n_1 -1)s_1^2 + (n_2 -1)s_2^2}{n_1 + n_2-2}\\) Standard deviation \\(\\sigma = \\sqrt{\\frac{\\sum{(X - \\mu)^2}}{N}}\\) \\(s =\\sqrt{\\frac{\\sum{(x - \\bar{x})^2}}{n-1}}\\) \\(s_{pooled} = \\sqrt{\\frac{(n_1 -1)s_1^2 + (n_2 -1)s_2^2}{n_1 + n_2-2}}\\) Cohen’s \\(d\\) or SMD \\(\\delta= \\frac{\\mu_{1} - \\mu_{2}}{\\sigma}\\) \\(d = \\frac{\\bar{x}_{1} - \\bar{x}_{2}}{s_{pooled}}\\) \\(d_{unbiased} = \\frac{\\bar{x}_{1} - \\bar{x}_{2}}{s_{pooled}} \\times [1 - \\frac{3}{4(n_1 + n_2)-9}]\\) "]
]
